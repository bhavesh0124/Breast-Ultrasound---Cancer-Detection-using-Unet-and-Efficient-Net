{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport glob, os\nimport tensorflow as tf\nimport logging\ntf.get_logger().setLevel(logging.ERROR)\nimport tensorflow_addons as tfa\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image, image_dataset_from_directory\n\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.optimizers import *\nfrom PIL import Image\nfrom skimage import data, io, filters\nfrom keras.losses import *\nfrom keras.metrics import *\nfrom tensorflow.keras.applications import EfficientNetB7, inception_v3","metadata":{"execution":{"iopub.status.busy":"2022-04-19T04:28:45.194990Z","iopub.execute_input":"2022-04-19T04:28:45.195252Z","iopub.status.idle":"2022-04-19T04:28:45.202119Z","shell.execute_reply.started":"2022-04-19T04:28:45.195224Z","shell.execute_reply":"2022-04-19T04:28:45.201473Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"dir_path = '../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/'","metadata":{"execution":{"iopub.status.busy":"2022-04-19T04:24:40.241869Z","iopub.execute_input":"2022-04-19T04:24:40.242120Z","iopub.status.idle":"2022-04-19T04:24:40.246606Z","shell.execute_reply.started":"2022-04-19T04:24:40.242091Z","shell.execute_reply":"2022-04-19T04:24:40.245763Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data = []\n!cp -r \"../input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT\" \"./\"\nos.makedirs(\"./images\") \nos.makedirs(\"./masks\") \n\nSHAPE = (250,250)\nfor dirname, _, filenames in os.walk(\"./Dataset_BUSI_with_GT\"):\n    if \"normal\" not in dirname:\n        for filename in filenames:\n            if \"mask\" not in filename:\n                d1 = dirname.split('/')[2]\n                d2 = os.path.join('./images', filename)\n                d3 = os.path.join('./masks',filename)\n                os.replace(dirname+\"/\"+filename.replace('.png','') + (\"_mask.png\"), \"./masks/\" + filename)\n                os.replace(dirname+\"/\"+filename, \"./images/\" + filename)\n\n                data.append([d1,d2,d3])\n                \ndf = pd.DataFrame(data, columns=['category','image','mask'])\ndf","metadata":{"execution":{"iopub.status.busy":"2022-04-19T04:24:40.600344Z","iopub.execute_input":"2022-04-19T04:24:40.600747Z","iopub.status.idle":"2022-04-19T04:24:52.736138Z","shell.execute_reply.started":"2022-04-19T04:24:40.600715Z","shell.execute_reply":"2022-04-19T04:24:52.735307Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = (300,300)\n\nfor i in df.itertuples():\n    img = io.imread(i.image)\n    mask = io.imread(i.mask)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T04:24:52.738211Z","iopub.execute_input":"2022-04-19T04:24:52.738502Z","iopub.status.idle":"2022-04-19T04:24:59.764410Z","shell.execute_reply.started":"2022-04-19T04:24:52.738467Z","shell.execute_reply":"2022-04-19T04:24:59.763538Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = (250,250)\n\nn=5\nsamples = df.sample(n=n, random_state=1)\nprint(samples.columns)\nprint(type(samples))\n\nfig, axs = plt.subplots(n,3,figsize=(n*5,n*10))\n\nfor idx,i in enumerate(samples.itertuples()):\n    mask = tf.io.read_file(i.mask)\n    img = tf.io.read_file(i.image)\n    \n    img = tf.image.decode_jpeg(img, channels=1)\n    mask = tf.image.decode_jpeg(mask, channels=1)\n    \n    mask = tf.image.convert_image_dtype(mask, tf.float32)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    \n    mirror = (mask+1)%2\n    reshaped = tf.image.resize(img, size=[SHAPE[0],SHAPE[1]])    \n    axs[idx,0].set_title(str(img.shape))\n    axs[idx,0].imshow(img)\n    axs[idx,1].imshow(mask)\n    axs[idx,2].set_title(str(\"mirror\"))\n    axs[idx,2].imshow(mirror)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T04:24:59.765849Z","iopub.execute_input":"2022-04-19T04:24:59.766093Z","iopub.status.idle":"2022-04-19T04:25:05.025385Z","shell.execute_reply.started":"2022-04-19T04:24:59.766060Z","shell.execute_reply":"2022-04-19T04:25:05.024500Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def process_img(file_path,shape=SHAPE,ismask=False):\n    img = tf.io.read_file(file_path)\n    img = tf.image.decode_jpeg(img, channels=1)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    img = tf.image.resize(img, size=[shape[0],shape[1]])\n    if ismask:\n        mirror = (img+1)%2\n        return tf.concat([img,mirror],2)\n    return img\n","metadata":{"execution":{"iopub.status.busy":"2022-04-19T04:25:17.013752Z","iopub.execute_input":"2022-04-19T04:25:17.014014Z","iopub.status.idle":"2022-04-19T04:25:17.020019Z","shell.execute_reply.started":"2022-04-19T04:25:17.013983Z","shell.execute_reply":"2022-04-19T04:25:17.019202Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class U_Net():\n    def __init__(self, inp=(572, 572, 1),min_filter=64,max_filter=1024, optimizer='Adam',loss= 'BinaryCrossentropy' , metrics = ['accuracy',AUC()]):\n        self.max_filter = max_filter\n        self.min_filter = min_filter\n        self.img_inp = Input(shape = inp)\n        down,cac,down_list = self.downsample()\n        lower,down_list = self.contracting_path(down,down_list)\n        upper,cac2 = self.upsample(lower,down_list)\n        out = Conv2D(2,(1), activation=\"softmax\", name='output')(upper)\n        self.out = out\n        self.model = keras.Model(inputs=self.img_inp, outputs=self.out)\n        \n        optimizer = tf.keras.optimizers.SGD(\n            learning_rate=0.01, momentum=0.9,  name=\"SGD\"\n        )\n        self.model.compile(optimizer=optimizer,loss=loss,metrics=metrics)\n        \n    def downsample(self):\n        k = self.min_filter\n\n        down_list = []\n        res = self.img_inp\n        while k < self.max_filter:\n            res = Conv2D(k,(3,3))(res)\n            res = ReLU()(res)\n            #rest = Dropout(0.3)(res)\n            res = Conv2D(k,(3,3))(res)\n            res = ReLU()(res)\n            #rest = Dropout(0.3)(res)\n            down_list.append(res)\n            cac = res\n            res = MaxPooling2D(pool_size=(2, 2),strides=2)(res)\n            curr = res\n            k*=2\n        return res,cac,down_list\n    \n    def upsample(self,res,down_list):\n        k = self.max_filter\n        i=0\n        while k > self.min_filter:\n            res = Conv2D(k/2,(3,3))(res)\n            res = ReLU()(res)\n            #rest = Dropout(0.3)(res)\n            k/=2\n            \n            if k > self.min_filter:\n                res = Conv2D(k/2,(3,3))(res)\n                res = ReLU()(res)\n                #rest = Dropout(0.3)(res)\n                res = UpSampling2D((2,2))(res)\n                left = down_list.pop()\n                res = self.crop_and_conc(left,res)\n                i+=1\n            else:\n                res = Conv2D(k,(3,3))(res)\n                res = ReLU()(res)\n                #rest = Dropout(0.3)(res)\n            cac = res\n            curr = res\n        return res,cac\n    \n    def contracting_path(self,down,down_list):\n        res = Conv2D(self.max_filter,(3,3))(down)\n        res = ReLU()(res)\n        #rest = Dropout(0.3)(res)\n        res = Conv2D(self.max_filter/2,(3,3))(res)\n        res = ReLU()(res)\n        #rest = Dropout(0.3)(res)\n        res = UpSampling2D((2,2))(res)\n        left = down_list.pop()\n        res = self.crop_and_conc(left,res)\n        return res,down_list\n    \n    \n    def crop_and_conc(self,left,right):\n        left = Cropping2D(cropping=int((left.shape[1]-right.shape[1])/2))(left)\n        right = Concatenate()([left,right])\n        return right\n ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-19T04:30:15.630697Z","iopub.execute_input":"2022-04-19T04:30:15.631511Z","iopub.status.idle":"2022-04-19T04:30:15.656991Z","shell.execute_reply.started":"2022-04-19T04:30:15.631467Z","shell.execute_reply":"2022-04-19T04:30:15.656178Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"shape = (300,300,1) #tuple for building the model\n\nmodel = U_Net(inp=shape)\nmodel.model.summary()\n\n#dot_img_file = 'model.png'\n#tf.keras.utils.plot_model(model.model, to_file=dot_img_file, show_shapes=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T04:30:16.021555Z","iopub.execute_input":"2022-04-19T04:30:16.022345Z","iopub.status.idle":"2022-04-19T04:30:16.256695Z","shell.execute_reply.started":"2022-04-19T04:30:16.022307Z","shell.execute_reply":"2022-04-19T04:30:16.255837Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from glob import glob\n\nx_files = glob('./images/*.png')\ny_files = glob('./masks/*.png')\nfiles_ds = tf.data.Dataset.from_tensor_slices((x_files, y_files))\nmask_shape = model.model.get_layer('output').output_shape\nprint(mask_shape[1:])\nfiles_ds = files_ds.map(lambda x, y: (process_img(x,shape), process_img(y,mask_shape[1:],ismask=True))).batch(1)\n\nprint(type(files_ds))","metadata":{"execution":{"iopub.status.busy":"2022-04-19T04:30:16.969947Z","iopub.execute_input":"2022-04-19T04:30:16.970246Z","iopub.status.idle":"2022-04-19T04:30:17.073382Z","shell.execute_reply.started":"2022-04-19T04:30:16.970212Z","shell.execute_reply":"2022-04-19T04:30:17.072642Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nLR = 1e-2\nepochs = 75\nhistory = model.model.fit(files_ds,epochs=epochs, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-04-19T04:30:17.714457Z","iopub.execute_input":"2022-04-19T04:30:17.714978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.title(\"Reconstruction Loss\")\nepochs=len(history.history['loss'])\nplt.plot(np.arange(0,epochs),history.history['loss'],label=\"Loss on Train Data\", marker='*',color='green')\n\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.xticks(np.arange(0,epochs,5),np.arange(0,epochs,5))\nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-18T06:04:25.840658Z","iopub.execute_input":"2022-04-18T06:04:25.840958Z","iopub.status.idle":"2022-04-18T06:04:26.039141Z","shell.execute_reply.started":"2022-04-18T06:04:25.840925Z","shell.execute_reply":"2022-04-18T06:04:26.037574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}